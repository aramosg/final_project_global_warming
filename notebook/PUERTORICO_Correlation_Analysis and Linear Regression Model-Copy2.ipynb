{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecd124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "## Basic libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "## Building Model\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "## Data Visualization\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker as ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53a654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>year</th>\n",
       "      <th>agriculture_value_added_constants</th>\n",
       "      <th>agriculture_value_added_percentage_gdp</th>\n",
       "      <th>annual_co2_emissions_tons</th>\n",
       "      <th>inflation_inflation_gdp_deflation</th>\n",
       "      <th>deaths_from_drought</th>\n",
       "      <th>deaths_from_extreme_temps</th>\n",
       "      <th>deaths_from_floods</th>\n",
       "      <th>...</th>\n",
       "      <th>economic_damages_from_storms_as_a_share_of_gdp</th>\n",
       "      <th>economic_damages_from_wildfires</th>\n",
       "      <th>economic_damages_as_a_share_of_gdp</th>\n",
       "      <th>economic_damages</th>\n",
       "      <th>economic_damages_thousands</th>\n",
       "      <th>people_affected_per_100k</th>\n",
       "      <th>number_of_deaths</th>\n",
       "      <th>population_population_growth_annual_percentage</th>\n",
       "      <th>population_population_total</th>\n",
       "      <th>temperature_change_temp_change_celsius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1893554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.665129</td>\n",
       "      <td>11475450</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1530347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2120.261216</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.714539</td>\n",
       "      <td>11791222</td>\n",
       "      <td>-1.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.094723</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.981389</td>\n",
       "      <td>12943093</td>\n",
       "      <td>-0.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2153300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>1979.191965</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.281715</td>\n",
       "      <td>13341199</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1756302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.601333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.407658</td>\n",
       "      <td>13356500</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code country_name  year  agriculture_value_added_constants  \\\n",
       "0          AFG  Afghanistan  1971                                NaN   \n",
       "1          AFG  Afghanistan  1972                                NaN   \n",
       "2          AFG  Afghanistan  1976                                NaN   \n",
       "3          AFG  Afghanistan  1978                                NaN   \n",
       "4          AFG  Afghanistan  1980                                NaN   \n",
       "\n",
       "   agriculture_value_added_percentage_gdp  annual_co2_emissions_tons  \\\n",
       "0                                     NaN                    1893554   \n",
       "1                                     NaN                    1530347   \n",
       "2                                     NaN                    1980859   \n",
       "3                                     NaN                    2153300   \n",
       "4                                     NaN                    1756302   \n",
       "\n",
       "   inflation_inflation_gdp_deflation  deaths_from_drought  \\\n",
       "0                                NaN                  0.0   \n",
       "1                                NaN                  0.0   \n",
       "2                                NaN                  0.0   \n",
       "3                                NaN                  0.0   \n",
       "4                                NaN                  0.0   \n",
       "\n",
       "   deaths_from_extreme_temps  deaths_from_floods  ...  \\\n",
       "0                        0.0                 0.0  ...   \n",
       "1                        0.0               150.0  ...   \n",
       "2                        0.0                51.0  ...   \n",
       "3                        0.0               120.0  ...   \n",
       "4                        0.0                 0.0  ...   \n",
       "\n",
       "   economic_damages_from_storms_as_a_share_of_gdp  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   economic_damages_from_wildfires  economic_damages_as_a_share_of_gdp  \\\n",
       "0                              0.0                            0.000000   \n",
       "1                              0.0                            0.000000   \n",
       "2                              0.0                            0.000000   \n",
       "3                              0.0                            0.393939   \n",
       "4                              0.0                            0.000000   \n",
       "\n",
       "   economic_damages  economic_damages_thousands  people_affected_per_100k  \\\n",
       "0               0.0                         0.0                  0.000000   \n",
       "1               0.0                         0.0               2120.261216   \n",
       "2               0.0                         0.0                618.094723   \n",
       "3           52000.0                     52000.0               1979.191965   \n",
       "4               0.0                         0.0                224.601333   \n",
       "\n",
       "   number_of_deaths  population_population_growth_annual_percentage  \\\n",
       "0               0.0                                        2.665129   \n",
       "1             150.0                                        2.714539   \n",
       "2              51.0                                        1.981389   \n",
       "3             120.0                                        1.281715   \n",
       "4               0.0                                       -0.407658   \n",
       "\n",
       "   population_population_total  temperature_change_temp_change_celsius  \n",
       "0                     11475450                                   0.652  \n",
       "1                     11791222                                  -1.089  \n",
       "2                     12943093                                  -0.295  \n",
       "3                     13341199                                   0.105  \n",
       "4                     13356500                                   0.690  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../Resources.2/general_dataset.csv\"\n",
    "df= pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db83bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>year</th>\n",
       "      <th>agriculture_value_added_constants</th>\n",
       "      <th>agriculture_value_added_percentage_gdp</th>\n",
       "      <th>annual_co2_emissions_tons</th>\n",
       "      <th>inflation_inflation_gdp_deflation</th>\n",
       "      <th>deaths_from_drought</th>\n",
       "      <th>deaths_from_extreme_temps</th>\n",
       "      <th>deaths_from_floods</th>\n",
       "      <th>...</th>\n",
       "      <th>economic_damages_from_storms_as_a_share_of_gdp</th>\n",
       "      <th>economic_damages_from_wildfires</th>\n",
       "      <th>economic_damages_as_a_share_of_gdp</th>\n",
       "      <th>economic_damages</th>\n",
       "      <th>economic_damages_thousands</th>\n",
       "      <th>people_affected_per_100k</th>\n",
       "      <th>number_of_deaths</th>\n",
       "      <th>population_population_growth_annual_percentage</th>\n",
       "      <th>population_population_total</th>\n",
       "      <th>temperature_change_temp_change_celsius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country_code, country_name, year, agriculture_value_added_constants, agriculture_value_added_percentage_gdp, annual_co2_emissions_tons, inflation_inflation_gdp_deflation, deaths_from_drought, deaths_from_extreme_temps, deaths_from_floods, deaths_from_storms, deaths_from_wildfires, people_affected_by_drought_per_100k, people_affected_by_extreme_temperatures_per_100k, people_affected_by_floods_per_100k, people_affected_by_storms_per_100k, people_affected_by_wildfires_per_100k, economic_damages_from_drought, economic_damages_from_drought_as_a_share_of_gdp, economic_damages_from_extreme_temperatures, economic_damages_from_extreme_temperatures_as_a_share_of_gdp, economic_damages_from_floods, economic_damages_from_floods_as_a_share_of_gdp, economic_damages_from_storms, economic_damages_from_storms_as_a_share_of_gdp, economic_damages_from_wildfires, economic_damages_as_a_share_of_gdp, economic_damages, economic_damages_thousands, people_affected_per_100k, number_of_deaths, population_population_growth_annual_percentage, population_population_total, temperature_change_temp_change_celsius]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pri_df= df[(df['country_name'] == 'Puerto Rico')]\n",
    "pri_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "080b08a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country_code',\n",
       " 'year',\n",
       " 'agriculture_value_added_constants',\n",
       " 'agriculture_value_added_percentage_gdp',\n",
       " 'annual_co2_emissions_tons',\n",
       " 'inflation_inflation_gdp_deflation',\n",
       " 'deaths_from_drought',\n",
       " 'deaths_from_extreme_temps',\n",
       " 'deaths_from_floods',\n",
       " 'deaths_from_storms',\n",
       " 'deaths_from_wildfires',\n",
       " 'people_affected_by_drought_per_100k',\n",
       " 'people_affected_by_extreme_temperatures_per_100k',\n",
       " 'people_affected_by_floods_per_100k',\n",
       " 'people_affected_by_storms_per_100k',\n",
       " 'people_affected_by_wildfires_per_100k',\n",
       " 'economic_damages_from_drought',\n",
       " 'economic_damages_from_drought_as_a_share_of_gdp',\n",
       " 'economic_damages_from_extreme_temperatures',\n",
       " 'economic_damages_from_extreme_temperatures_as_a_share_of_gdp',\n",
       " 'economic_damages_from_floods',\n",
       " 'economic_damages_from_floods_as_a_share_of_gdp',\n",
       " 'economic_damages_from_storms',\n",
       " 'economic_damages_from_storms_as_a_share_of_gdp',\n",
       " 'economic_damages_from_wildfires',\n",
       " 'economic_damages_as_a_share_of_gdp',\n",
       " 'economic_damages',\n",
       " 'economic_damages_thousands',\n",
       " 'people_affected_per_100k',\n",
       " 'number_of_deaths',\n",
       " 'population_population_growth_annual_percentage',\n",
       " 'population_population_total',\n",
       " 'temperature_change_temp_change_celsius']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pri_df= pri_df.drop(['country_name'], axis=1)\n",
    "pri_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945bbce0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hti_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17384/2935826604.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpri_df\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpri_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhti_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1988\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpri_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m2020\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpri_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpri_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hti_df' is not defined"
     ]
    }
   ],
   "source": [
    "pri_df= pri_df[(hti_df['year'] >= 1988) & (pri_df['year'] <= 2020)]\n",
    "pri_df.set_index('year',inplace = True)\n",
    "pri_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d99cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_df = pri_df.drop([\n",
    " 'country_code',\n",
    " 'deaths_from_drought',\n",
    " 'deaths_from_extreme_temps',\n",
    " 'deaths_from_floods',\n",
    " 'deaths_from_storms',\n",
    " 'deaths_from_wildfires',\n",
    " 'people_affected_by_drought_per_100k',\n",
    " 'people_affected_by_extreme_temperatures_per_100k',\n",
    " 'people_affected_by_floods_per_100k',\n",
    " 'people_affected_by_storms_per_100k',\n",
    " 'people_affected_by_wildfires_per_100k',\n",
    " 'economic_damages_from_drought',\n",
    " 'economic_damages_from_drought_as_a_share_of_gdp',\n",
    " 'economic_damages_from_extreme_temperatures',\n",
    " 'economic_damages_from_extreme_temperatures_as_a_share_of_gdp',\n",
    " 'economic_damages_from_floods',\n",
    " 'economic_damages_from_floods_as_a_share_of_gdp',\n",
    " 'economic_damages_from_storms',\n",
    " 'economic_damages_from_storms_as_a_share_of_gdp',\n",
    " 'economic_damages_from_wildfires',\n",
    " 'economic_damages',\n",
    " 'economic_damages_thousands',\n",
    "], axis=1)\n",
    "pri_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f6893",
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(6, 6))\n",
    "sb.distplot(\n",
    "    pri_df.economic_damages_as_a_share_of_gdp,\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Distribución original\", fontsize = 'medium')\n",
    "axes[0].set_xlabel('precio', fontsize='small') \n",
    "axes[0].tick_params(labelsize = 6)\n",
    "\n",
    "sb.distplot(\n",
    "    np.sqrt(hti_df.economic_damages_as_a_share_of_gdp),\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Transformación raíz cuadrada\", fontsize = 'medium')\n",
    "axes[1].set_xlabel('sqrt(economic_damages_as_a_share_of_gdp)', fontsize='small') \n",
    "axes[1].tick_params(labelsize = 6)\n",
    "\n",
    "sb.distplot(\n",
    "    np.log(hti_df.economic_damages_as_a_share_of_gdp),\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[2]\n",
    ")\n",
    "axes[2].set_title(\"Transformación logarítmica\", fontsize = 'medium')\n",
    "axes[2].set_xlabel('log(economic_damages_as_a_share_of_gdp)', fontsize='small') \n",
    "axes[2].tick_params(labelsize = 6)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd215e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fitter import Fitter\n",
    "distribuciones = ['cauchy', 'chi2', 'expon',  'exponpow', 'gamma',\n",
    "                  'norm', 'powerlaw', 'beta', 'logistic', 'lognorm']\n",
    "\n",
    "fitter = Fitter(hti_df.economic_damages_as_a_share_of_gdp, distributions=distribuciones)\n",
    "fitter.fit()\n",
    "fitter.summary(Nbest=10, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab0336",
   "metadata": {},
   "source": [
    "Pairplot() function from the Seaborn library will output a figure containing histogram and scatter plot between each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41915f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data using scatter plot and histogram\n",
    "#sb.set_palette('colorblind')\n",
    "#sb.pairplot(data=hti_df, height=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd07442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_df.corr ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_corr_df = pri_df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sb.heatmap(hti_corr_df, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41df473",
   "metadata": {},
   "source": [
    "### CORRELATION TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b66a313",
   "metadata": {},
   "source": [
    "El análisis gráfico hecho previamente y los test estadísticos mostraron evidencias de que no se puede asumir normalidad en las variables de desastres. Siendo estrictos, este hecho excluye la posibilidad de utilizar el coeficiente de Pearson, dejando como alternativas el de Spearman o Kendall. Sin embargo, dado que la distribución no se aleja mucho de la normalidad y de que el coeficiente de Pearson tiene cierta robustez, a fines prácticos sí que se podría utilizar siempre y cuando se tenga en cuenta este hecho y se comunique en los resultados. Otra posibilidad es tratar de transformar las variables para mejorar su distribución, por ejemplo, aplicando el logaritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99389d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlación Pearson: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['population_population_total'], method='pearson'))\n",
    "print('Correlación spearman: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['population_population_total'], method='spearman'))\n",
    "print('Correlación kendall: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['population_population_total'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pri_df.population_population_total , pri_df.temperature_change_temp_change_celsius )\n",
    "plt.xlabel('population_population_total')\n",
    "plt.ylabel('temperature_change_temp_change_celsius')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlación Pearson: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['population_population_growth_annual_percentage'], method='pearson'))\n",
    "print('Correlación spearman: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['population_population_growth_annual_percentage'], method='spearman'))\n",
    "print('Correlación kendall: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['population_population_growth_annual_percentage'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pri_df.population_population_growth_annual_percentage, pri_df.temperature_change_temp_change_celsius )\n",
    "plt.xlabel('population_population_growth_annual_percentage')\n",
    "plt.ylabel('temperature_change_temp_change_celsius')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafb202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlación Pearson: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['annual_co2_emissions_tons'], method='pearson'))\n",
    "print('Correlación spearman: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['annual_co2_emissions_tons'], method='spearman'))\n",
    "print('Correlación kendall: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['annual_co2_emissions_tons'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a356ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pri_df.annual_co2_emissions_tons, pri_df.temperature_change_temp_change_celsius )\n",
    "plt.xlabel('annual_co2_emissions_tons')\n",
    "plt.ylabel('temperature_change_temp_change_celsius')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlación Pearson: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['economic_damages_as_a_share_of_gdp'], method='pearson'))\n",
    "print('Correlación spearman: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['economic_damages_as_a_share_of_gdp'], method='spearman'))\n",
    "print('Correlación kendall: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['economic_damages_as_a_share_of_gdp'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94da0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hti_df.economic_damages_as_a_share_of_gdp, hti_df.temperature_change_temp_change_celsius )\n",
    "plt.xlabel('economic_damages_as_a_share_of_gdp')\n",
    "plt.ylabel('temperature_change_temp_change_celsius')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación sin outlier\n",
    "#r, p = stats.pearsonr(np.delete(a, 5), np.delete(b, 5))\n",
    "#print(f\"Correlación Pearson sin outlier: r={r}, p-value={p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00dbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlación Pearson: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['number_of_deaths'], method='pearson'))\n",
    "print('Correlación spearman: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['number_of_deaths'], method='spearman'))\n",
    "print('Correlación kendall: ', pri_df['temperature_change_temp_change_celsius'].corr(hti_df['number_of_deaths'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e032b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hti_df.number_of_deaths, pri_df.temperature_change_temp_change_celsius )\n",
    "plt.xlabel('number_of_deaths')\n",
    "plt.ylabel('temperature_change_temp_change_celsius')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación sin outlier\n",
    "#Pendiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlación Pearson: ', pri_df['number_of_deaths'].corr(pri_df['economic_damages_as_a_share_of_gdp'], method='pearson'))\n",
    "print('Correlación spearman: ', pri_df['number_of_deaths'].corr(pri_df['economic_damages_as_a_share_of_gdp'], method='spearman'))\n",
    "print('Correlación kendall: ', pri_df['number_of_deaths'].corr(pri_df['economic_damages_as_a_share_of_gdp'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f653b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pri_df.number_of_deaths, pri_df.economic_damages_as_a_share_of_gdp )\n",
    "plt.xlabel('number_of_deaths')\n",
    "plt.ylabel('economic_damages_as_a_share_of_gdp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación sin outlier\n",
    "#Pendiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339195b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlación Pearson: ', pri_df['people_affected_per_100k'].corr(pri_df['economic_damages_as_a_share_of_gdp'], method='pearson'))\n",
    "print('Correlación spearman: ', pri_df['people_affected_per_100k'].corr(pri_df['economic_damages_as_a_share_of_gdp'], method='spearman'))\n",
    "print('Correlación kendall: ', pri_df['people_affected_per_100k'].corr(pri_df['economic_damages_as_a_share_of_gdp'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e22c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pri_df.people_affected_per_100k, pri_df.economic_damages_as_a_share_of_gdp )\n",
    "plt.xlabel('people_affected_per_100k')\n",
    "plt.ylabel('economic_damages_as_a_share_of_gdp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81941846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación sin outlier\n",
    "#Pendiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlación Pearson: ', pri_df['economic_damages_as_a_share_of_gdp'].corr(pri_df['inflation_inflation_gdp_deflation'], method='pearson'))\n",
    "print('Correlación spearman: ', pri_df['economic_damages_as_a_share_of_gdp'].corr(pri_df['inflation_inflation_gdp_deflation'], method='spearman'))\n",
    "print('Correlación kendall: ', pri_df['economic_damages_as_a_share_of_gdp'].corr(pri_df['inflation_inflation_gdp_deflation'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49dfc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pri_df.inflation_inflation_gdp_deflation, pri_df.economic_damages_as_a_share_of_gdp )\n",
    "plt.xlabel('inflation_inflation_gdp_deflation')\n",
    "plt.ylabel('economic_damages_as_a_share_of_gdp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlación Pearson: ', pri_df['inflation_inflation_gdp_deflation'].corr(pri_df['agriculture_value_added_constants'], method='pearson'))\n",
    "print('Correlación spearman: ', pri_df['inflation_inflation_gdp_deflation'].corr(pri_df['agriculture_value_added_constants'], method='spearman'))\n",
    "print('Correlación kendall: ', pri_df['inflation_inflation_gdp_deflation'].corr(pri_df['agriculture_value_added_constants'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pri_df.inflation_inflation_gdp_deflation, pri_df.agriculture_value_added_constants)\n",
    "plt.xlabel('inflation_inflation_gdp_deflation')\n",
    "plt.ylabel('agriculture_value_added_constants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506efa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de correlación y significancia con Scipy\n",
    "# ==============================================================================\n",
    "r, p = stats.pearsonr(pri_df['temperature_change_temp_change_celsius'], pri_df['population_population_total'])\n",
    "print(f\"Correlación Pearson: r={r}, p-value={p}\")\n",
    "\n",
    "r, p = stats.spearmanr(pri_df['temperature_change_temp_change_celsius'], pri_df['population_population_total'], nan_policy='omit')\n",
    "print(f\"Correlación Spearman: r={r}, p-value={p}\")\n",
    "\n",
    "r, p = stats.kendalltau(pri_df['temperature_change_temp_change_celsius'], pri_df['population_population_total'], nan_policy='omit')\n",
    "print(f\"Correlación Pearson: r={r}, p-value={p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb102e",
   "metadata": {},
   "source": [
    "## Normalizando una variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ND_2 = pri_df['number_of_deaths']/np.linalg.norm(pri_df['number_of_deaths'])\n",
    "pri_df = pri_df.assign(normalized_ND_2=normalized_ND_2)\n",
    "pri_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlación Pearson: ', pri_df['temperature_change_temp_change_celsius'].corr(pri_df['normalized_ND_2'], method='pearson'))\n",
    "print('Correlación spearman: ', pri_df['temperature_change_temp_change_celsius'].corr(pri_df['normalized_ND_2'], method='spearman'))\n",
    "print('Correlación kendall: ', pri_df['temperature_change_temp_change_celsius'].corr(pri_df['normalized_ND_2'], method='kendall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_EDPGDP = pri_df['economic_damages_as_a_share_of_gdp']/np.linalg.norm(pri_df['economic_damages_as_a_share_of_gdp'])\n",
    "pri_df = pri_df.assign(normalized_EDPGDP=normalized_EDPGDP)\n",
    "pri_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set independent and dependent variables\n",
    "X = pri_df[['population_population_total','temperature_change_temp_change_celsius','annual_co2_emissions_tons']]\n",
    "y = pri_df['normalized_EDPGDP']\n",
    "\n",
    "# Initialize model from sklearn and fit it into our data\n",
    "regr = linear_model.LinearRegression()\n",
    "model = regr.fit(X, y)\n",
    "\n",
    "y_pred = regr.predict(X)\n",
    "print(y_pred.shape)\n",
    "\n",
    "print('Intercept:', model.intercept_)\n",
    "print('Coefficients:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ccb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hti_df[['population_population_total','temperature_change_temp_change_celsius','annual_co2_emissions_tons']]\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "olsmod = sm.OLS(hti_df['normalized_EDPGDP'], X).fit()\n",
    "print(olsmod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0367fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R2 score:', olsmod.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e184492",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F-statistic:', olsmod.fvalue)\n",
    "print('Probability of observing value at least as high as F-statistic:', olsmod.f_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610d83e",
   "metadata": {},
   "source": [
    "Because our f_pvalue is lower than 0.05 we can conclude that our model performs better than other simpler model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(olsmod.pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ddd0ba",
   "metadata": {},
   "source": [
    "All of our independent variables,  have p-value mayor than 0.05 which shows that there is not sufficient evidence that there variables affects our dependet variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c761e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set independent and dependent variables\n",
    "X = pri_df[['normalized_EDPGDP']]\n",
    "y = pri_df['inflation_inflation_gdp_deflation']\n",
    "\n",
    "# Initialize model from sklearn and fit it into our data\n",
    "regr = linear_model.LinearRegression()\n",
    "model = regr.fit(X, y)\n",
    "\n",
    "print('Intercept:', model.intercept_)\n",
    "print('Coefficients:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f505cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pri_df[['normalized_EDPGDP']]\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "olsmod = sm.OLS(hti_df['inflation_inflation_gdp_deflation'], X).fit()\n",
    "print(olsmod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa11b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(olsmod.pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba44c0e",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d14ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3594a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_df = pri_df.drop(['normalized_ND_2','normalized_EDPGDP'],axis=1)\n",
    "pri_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "std_scaler = StandardScaler()\n",
    " \n",
    "df_scaled = std_scaler.fit_transform(pri_df.to_numpy())\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=[\n",
    " 'agriculture_value_added_constants',\n",
    " 'agriculture_value_added_percentage_gdp',\n",
    " 'annual_co2_emissions_tons',\n",
    " 'inflation_inflation_gdp_deflation',\n",
    " 'economic_damages_as_a_share_of_gdp',\n",
    " 'people_affected_per_100k',\n",
    " 'number_of_deaths',\n",
    " 'population_population_growth_annual_percentage',\n",
    " 'population_population_total',\n",
    " 'temperature_change_temp_change_celsius',\n",
    "])\n",
    " \n",
    "print(\"Scaled Dataset Using StandardScaler\")\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfacf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f0235",
   "metadata": {},
   "source": [
    "### Dependent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59c064",
   "metadata": {},
   "source": [
    "La variable \"economic_damages_as_a_share_of_gdp\" tiene una distribución asimétrica con una cola positiva. Este tipo de distribución suele visualizarse mejor tras aplicar el logarítmica o la raíz cuadrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a26bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(6, 6))\n",
    "sb.distplot(\n",
    "    df_scaled.economic_damages_as_a_share_of_gdp,\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Distribución original\", fontsize = 'medium')\n",
    "axes[0].set_xlabel('precio', fontsize='small') \n",
    "axes[0].tick_params(labelsize = 6)\n",
    "\n",
    "sb.distplot(\n",
    "    np.sqrt(df_scaled.economic_damages_as_a_share_of_gdp),\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Transformación raíz cuadrada\", fontsize = 'medium')\n",
    "axes[1].set_xlabel('sqrt(economic_damages_as_a_share_of_gdp)', fontsize='small') \n",
    "axes[1].tick_params(labelsize = 6)\n",
    "\n",
    "sb.distplot(\n",
    "    np.log(df_scaled.economic_damages_as_a_share_of_gdp),\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[2]\n",
    ")\n",
    "axes[2].set_title(\"Transformación logarítmica\", fontsize = 'medium')\n",
    "axes[2].set_xlabel('log(economic_damages_as_a_share_of_gdp)', fontsize='small') \n",
    "axes[2].tick_params(labelsize = 6)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitter import Fitter\n",
    "distribuciones = ['cauchy', 'chi2', 'expon',  'exponpow', 'gamma',\n",
    "                  'norm', 'powerlaw', 'beta', 'logistic', 'lognorm']\n",
    "\n",
    "fitter = Fitter(df_scaled.economic_damages_as_a_share_of_gdp, distributions=distribuciones)\n",
    "fitter.fit()\n",
    "fitter.summary(Nbest=10, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecabdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de distribución para cada variable numérica\n",
    "# ==============================================================================\n",
    "# Ajustar número de subplots en función del número de columnas\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(9, 5))\n",
    "axes = axes.flat\n",
    "columnas_numeric = df_scaled.select_dtypes(include=['float64', 'int']).columns\n",
    "columnas_numeric = columnas_numeric.drop('economic_damages_as_a_share_of_gdp')\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sb.regplot(\n",
    "        x           = df_scaled[colum],\n",
    "        y           = df_scaled['economic_damages_as_a_share_of_gdp'],\n",
    "        color       = \"gray\",\n",
    "        marker      = '.',\n",
    "        scatter_kws = {\"alpha\":0.4},\n",
    "        line_kws    = {\"color\":\"r\",\"alpha\":0.7},\n",
    "        ax          = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f\"(economic_damages_as_a_share_of_gdp) vs {colum}\", fontsize = 7, fontweight = \"bold\")\n",
    "    #axes[i].ticklabel_format(style='sci', scilimits=(-4,4), axis='both')\n",
    "    axes[i].yaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].tick_params(labelsize = 6)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "\n",
    "# Se eliminan los axes vacíos\n",
    "for i in [8]:\n",
    "    fig.delaxes(axes[i])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Correlación con economic_damages_as_a_share_of_gdp', fontsize = 10, fontweight = \"bold\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e963d81",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820aa09",
   "metadata": {},
   "source": [
    "### ROBUST MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec7235",
   "metadata": {},
   "source": [
    "### linear regression on a dataset with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression on a dataset with outliers\n",
    "from random import random\n",
    "from random import randint\n",
    "from random import seed\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# prepare the dataset\n",
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "# summarize shape\n",
    "print(X.shape, y.shape)\n",
    "# scatter plot of input vs output\n",
    "pyplot.scatter(X, y)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define model evaluation method\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    # force scores to be positive\n",
    "    return absolute(scores)\n",
    "\n",
    "\n",
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "# define the model\n",
    "model = LinearRegression()\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y, model)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "\n",
    "\n",
    "# Calculating the parameters using the least square method\n",
    "theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "print(f'The parameters of the line: {theta}')\n",
    "\n",
    "# Now, calculating the y-axis values against x-values according to\n",
    "# the parameters theta0 and theta1\n",
    "y_line = X.dot(theta)\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, y_line, 'r')\n",
    "plt.title('Best fit line using regression method')\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc02512",
   "metadata": {},
   "source": [
    "### Huber regression on a dataset with outliers - Robust model-\n",
    "La regresión de Huber es un tipo de regresión robusta que es consciente de la posibilidad de valores atípicos en un conjunto de datos y les asigna menos peso que otros ejemplos en el conjunto de datos.\n",
    "\n",
    "Podemos usar la regresión de Huber a través de la clase HuberRegressor en scikit-learn. El argumento \" épsilon \" controla lo que se considera un valor atípico, donde los valores más pequeños consideran más valores atípicos de los datos y, a su vez, hacen que el modelo sea más robusto para los valores atípicos. El valor predeterminado es 1,35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd4600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huber regression on a dataset with outliers\n",
    "from random import random\n",
    "from random import randint\n",
    "from random import seed\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare the dataset\n",
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "\n",
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define model evaluation method\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    # force scores to be positive\n",
    "    return absolute(scores)\n",
    " \n",
    "# load dataset\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "# define the model\n",
    "model = HuberRegressor()\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y, model)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4764bb5",
   "metadata": {},
   "source": [
    "### Regresión RANSAC\n",
    "\n",
    "Random Sample Consensus , o RANSAC para abreviar, es otro algoritmo de regresión robusto.\n",
    "\n",
    "RANSAC intenta separar los datos en valores atípicos e internos y ajusta el modelo en los valores internos.\n",
    "\n",
    "La biblioteca scikit-learn proporciona una implementación a través de la clase RANSACRegressor ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f42b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ransac regression on a dataset with outliers\n",
    "from random import random\n",
    "from random import randint\n",
    "from random import seed\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# prepare the dataset\n",
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    " \n",
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define model evaluation method\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    # force scores to be positive\n",
    "    return absolute(scores)\n",
    "evaluate_model(X, y, model).any()\n",
    " \n",
    "# load dataset\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "# define the model\n",
    "model = RANSACRegressor()\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y, model)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "# plot the line of best fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8b7de",
   "metadata": {},
   "source": [
    "### Regresión de Theil Sen\n",
    "La regresión de Theil Sen implica ajustar modelos de regresión múltiple en subconjuntos de los datos de entrenamiento y combinar los coeficientes al final.\n",
    "\n",
    "El scikit-learn proporciona una implementación a través de la clase TheilSenRegressor ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theilsen regression on a dataset with outliers\n",
    "from random import random\n",
    "from random import randint\n",
    "from random import seed\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# prepare the dataset\n",
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define model evaluation method\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    # force scores to be positive\n",
    "    return absolute(scores)\n",
    " \n",
    "# plot the dataset and the model's line of best fit\n",
    "def plot_best_fit(X, y, model):\n",
    "\t# fit the model on all data\n",
    "\tmodel.fit(X.values.reshape(-1, 1), y)\n",
    "\t# calculate outputs for grid across the domain\n",
    "\ty_pred = model.predict(X.values.reshape(-1, 1))\n",
    "\t# plot the line of best fit\n",
    "\tpyplot.plot(X, y_pred, label=type(model).__name__)\n",
    " \n",
    "# load dataset\n",
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k','temperature_change_temp_change_celsius', 'number_of_deaths']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "# define the model\n",
    "model = TheilSenRegressor()\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y, model)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "#plot the line of best fit\n",
    "#plot_best_fit(X, y_pred, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e19d9",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba731c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compare robust regression algorithms on a regression dataset with outliers\n",
    "from random import random\n",
    "from random import randint\n",
    "from random import seed\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# prepare the dataset\n",
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    " \n",
    "# dictionary of model names and model objects\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['Linear'] = LinearRegression()\n",
    "    models['Huber'] = HuberRegressor()\n",
    "    models['RANSAC'] = RANSACRegressor()\n",
    "    models['TheilSen'] = TheilSenRegressor()\n",
    "    return models\n",
    " \n",
    "# evaluate a model\n",
    "def evalute_model(X, y, model, name):\n",
    "    # define model evaluation method\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    # force scores to be positive\n",
    "    scores = absolute(scores)\n",
    "    return scores\n",
    " \n",
    "# load the dataset\n",
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "# retrieve models\n",
    "models = get_models()\n",
    "results = dict()\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tresults[name] = evalute_model(X, y, model, name)\n",
    "\t# summarize progress\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(results[name]), std(results[name])))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results.values(), labels=results.keys(), showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f09ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot line of best for multiple robust regression algorithms\n",
    "from random import random\n",
    "from random import randint\n",
    "from random import seed\n",
    "from numpy import arange\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# prepare the dataset\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "\n",
    "print (X.shape)\n",
    "\n",
    "# dictionary of model names and model objects\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(LinearRegression())\n",
    "\tmodels.append(HuberRegressor())\n",
    "\tmodels.append(RANSACRegressor())\n",
    "\tmodels.append(TheilSenRegressor())\n",
    "\treturn models\n",
    " \n",
    "# plot the dataset and the model's line of best fit\n",
    "def plot_best_fit(X, y, model):\n",
    "\t# fit the model on all data\n",
    "\tmodel.fit(X.values.reshape(-1, 1), y)\n",
    "\t# calculate outputs for grid across the domain\n",
    "\ty_pred = model.predict(X.values.reshape(-1, 1))\n",
    "\t# plot the line of best fit\n",
    "\tpyplot.plot(X, y_pred, label=type(model).__name__)\n",
    " \n",
    "# load the dataset\n",
    "X = df_scaled['people_affected_per_100k']\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "\n",
    "# define a uniform grid across the input domain\n",
    "xaxis = arange(X.min(), X.max(), 0.01)\n",
    "for model in get_models():\n",
    "\n",
    "# plot the line of best fit\n",
    "\tplot_best_fit(X, y_pred, model)\n",
    "# plot the dataset\n",
    "pyplot.scatter(X, y)\n",
    "# show the plot\n",
    "pyplot.title('Robust Regression')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e92ee3",
   "metadata": {},
   "source": [
    "### Training and testing the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k','temperature_change_temp_change_celsius', 'number_of_deaths']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Separo los datos de \"train\" en entrenamiento y prueba para probar los algoritmos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Initialize model from sklearn and fit it into our data\n",
    "regr = linear_model.LinearRegression()\n",
    "#Entreno el modelo\n",
    "model = regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizo una predicción\n",
    "Y_pred_multiple = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred_multiple)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ae0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATOS DEL MODELO REGRESIÓN LINEAL MULTIPLE')\n",
    "print()\n",
    "print('Valor de las pendientes o coeficientes \"a\":')\n",
    "print(regr.coef_)\n",
    "print('Valor de la intersección o coeficiente \"b\":')\n",
    "print(regr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precisión del modelo:')\n",
    "print(regr.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bdc112",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train, prepend=True)\n",
    "modelo = sm.OLS(endog=y_train, exog=X_train,)\n",
    "modelo = modelo.fit()\n",
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f21307",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelo.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervalos de confianza para los coeficientes del modelo\n",
    "intervalos_ci = modelo.conf_int(alpha=0.05)\n",
    "intervalos_ci.columns = ['2.5%', '97.5%']\n",
    "intervalos_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6ccdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "613558f5",
   "metadata": {},
   "source": [
    "### Complete model without split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set independent and dependent variables\n",
    "X = df_scaled[['annual_co2_emissions_tons',\n",
    " 'inflation_inflation_gdp_deflation',\n",
    " 'people_affected_per_100k',\n",
    " 'number_of_deaths',\n",
    " 'population_population_growth_annual_percentage',\n",
    " 'population_population_total',\n",
    " 'temperature_change_temp_change_celsius']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "\n",
    "# Initialize model from sklearn and fit it into our data\n",
    "regr = linear_model.LinearRegression()\n",
    "model = regr.fit(X, y)\n",
    "\n",
    "print('Intercept:', model.intercept_)\n",
    "print('Coefficients:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79038f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d249a496",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95cd640",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled[['annual_co2_emissions_tons',\n",
    " 'inflation_inflation_gdp_deflation',\n",
    " 'people_affected_per_100k',\n",
    " 'number_of_deaths',\n",
    " 'population_population_growth_annual_percentage',\n",
    " 'population_population_total',\n",
    " 'temperature_change_temp_change_celsius']]\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "olsmod_scaled = sm.OLS(df_scaled['economic_damages_as_a_share_of_gdp'], X).fit()\n",
    "print(olsmod_scaled.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8560383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R2 score:', olsmod_scaled.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb731886",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F-statistic:', olsmod_scaled.fvalue)\n",
    "print('Probability of observing value at least as high as F-statistic:', olsmod_scaled.f_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ef0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(olsmod_scaled.pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d2d29",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed4fde5",
   "metadata": {},
   "source": [
    "### Modelo OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22abacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "\n",
    "# Initialize model from sklearn and fit it into our data\n",
    "regr = linear_model.LinearRegression()\n",
    "model = regr.fit(X, y)\n",
    "\n",
    "print('Intercept:', model.intercept_)\n",
    "print('Coefficients:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled[['people_affected_per_100k',]]\n",
    "X = sm.add_constant(X) # adding a constant\n",
    "\n",
    "olsmod_scaled = sm.OLS(df_scaled['economic_damages_as_a_share_of_gdp'], X).fit()\n",
    "print(olsmod_scaled.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R2 score:', olsmod_scaled.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F-statistic:', olsmod_scaled.fvalue)\n",
    "print('Probability of observing value at least as high as F-statistic:', olsmod_scaled.f_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d61fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(olsmod_scaled.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c541d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled['residual'] = olsmod_scaled.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7bc7f",
   "metadata": {},
   "source": [
    "### Assumption Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a11e86",
   "metadata": {},
   "source": [
    "#### Linearity:\n",
    "This assumes that there is a linear relationship between the independent variables and the dependent variable. In our case since we have multiple independent variables, we can do this by using a scatter plot to see our predicted values versus the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3932f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled['predictions'] = olsmod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the observed vs predicted values\n",
    "sb.lmplot(x='economic_damages_as_a_share_of_gdp', y='predictions', data=df_scaled, fit_reg=False, size=5)\n",
    "    \n",
    "# Plotting the diagonal line\n",
    "line_coords = np.arange(df_scaled[['economic_damages_as_a_share_of_gdp', 'predictions']].min().min()-10, \n",
    "                        df_scaled[['economic_damages_as_a_share_of_gdp', 'predictions']].max().max()+10)\n",
    "plt.plot(line_coords, line_coords,  # X and y points\n",
    "         color='darkorange', linestyle='--')\n",
    "\n",
    "plt.ylabel('predictions', fontsize=14)\n",
    "plt.xlabel('economic_damages_as_a_share_of_gdp', fontsize=14)\n",
    "plt.title('Linearity Assumption', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c847d9",
   "metadata": {},
   "source": [
    "The scatter plots show residual point dont spread around the diagonal line, so we can assume that there isnt linear relationship between our independent and dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f68ed",
   "metadata": {},
   "source": [
    "#### Normality:\n",
    "This assumes that the error terms of the model are normally distributed. We will examine the normality of the residuals by plotting it into histogram and looking at the p-value from the Anderson-Darling test for normality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb27cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import normal_ad\n",
    "\n",
    "# Performing the test on the residuals\n",
    "p_value = normal_ad(df_scaled['residual'])[1]\n",
    "print('p-value from the test Anderson-Darling test below 0.05 generally means non-normal:', p_value)\n",
    "\n",
    "# Plotting the residuals distribution\n",
    "plt.subplots(figsize=(8, 4))\n",
    "plt.title('Distribution of Residuals', fontsize=18)\n",
    "sb.distplot(df_scaled['residual'])\n",
    "plt.show()\n",
    "\n",
    "# Reporting the normality of the residuals\n",
    "if p_value < 0.05:\n",
    "    print('Residuals are not normally distributed')\n",
    "else:\n",
    "    print('Residuals are normally distributed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a8c63",
   "metadata": {},
   "source": [
    "#### Multicollinearity:\n",
    "This assumes that the predictors used in the regression are not correlated with each other. To identify if there are any correlation between our predictors we can calculate the Pearson correlation coefficient between each column in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_scaled[['people_affected_per_100k','economic_damages_as_a_share_of_gdp']].corr()\n",
    "print('Pearson correlation coefficient matrix of each variables:\\n', corr)\n",
    "\n",
    "# Generate a mask for the diagonal cell\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "np.fill_diagonal(mask, val=True)\n",
    "\n",
    "# Initialize matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sb.diverging_palette(220, 10, as_cmap=True, sep=100)\n",
    "cmap.set_bad('grey')\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sb.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0, linewidths=.5)\n",
    "fig.suptitle('Pearson correlation coefficient matrix', fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79985c4",
   "metadata": {},
   "source": [
    "#### Autocorrelation\n",
    "Autocorrelation is correlation of the errors (residuals) over time. Used when data are collected over time to detect if autocorrelation is present. Autocorrelation exists if residuals in one time period are related to residuals in another period. We can detect autocorrelation by performing Durbin-Watson test to determine if either positive or negative correlation is present. In this step we will use the durbin_watson () function from statsmodel to calculate our Durbin-Watson score and then assess the value with the following condition:\n",
    "\n",
    "If the Durbin-Watson score is less than 1.5 then there is a positive autocorrelation and the assumption is not satisfied\n",
    "\n",
    "\n",
    "If the Durbin-Watson score is between 1.5 and 2.5 then there is no autocorrelation and the assumption is satisfied\n",
    "\n",
    "\n",
    "If the Durbin-Watson score is more than 2.5 then there is a negative autocorrelation and the assumption is not satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "durbinWatson = durbin_watson(df_scaled['residual'])\n",
    "\n",
    "print('Durbin-Watson:', durbinWatson)\n",
    "if durbinWatson < 1.5:\n",
    "    print('Signs of positive autocorrelation', '\\n')\n",
    "    print('Assumption not satisfied')\n",
    "elif durbinWatson > 2.5:\n",
    "    print('Signs of negative autocorrelation', '\\n')\n",
    "    print('Assumption not satisfied')\n",
    "else:\n",
    "    print('Little to no autocorrelation', '\\n')\n",
    "    print('Assumption satisfied')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f19d18",
   "metadata": {},
   "source": [
    "#### Homoscedasticity\n",
    "This assumes homoscedasticity, which is the same variance within our error terms. Heteroscedasticity, the violation of homoscedasticity, occurs when we don’t have an even variance across the error terms. To detect homoscedasticity, we can plot our residual and see if the variance appears to be uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113bf107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the residuals\n",
    "plt.subplots(figsize=(8, 4))\n",
    "plt.scatter(x=df_scaled.index, y=df_scaled.residual, alpha=0.8)\n",
    "plt.plot(np.repeat(0, len(df_scaled.index)+2), color='darkorange', linestyle='--')\n",
    "\n",
    "plt.ylabel('Residual', fontsize=14)\n",
    "plt.xlabel('year', fontsize=14)\n",
    "plt.title('Homescedasticity Assumption', fontsize=16)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e6bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a746708",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aa5215",
   "metadata": {},
   "source": [
    "### Huber Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23286d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huber regression on a dataset with outliers\n",
    "from random import random\n",
    "from random import randint\n",
    "from random import seed\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare the dataset\n",
    "# Set independent and dependent variables\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "\n",
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define model evaluation method\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    # force scores to be positive\n",
    "    return absolute(scores)\n",
    " \n",
    "# load dataset\n",
    "X = df_scaled[['people_affected_per_100k']]\n",
    "y = df_scaled['economic_damages_as_a_share_of_gdp']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Separo los datos de \"train\" en entrenamiento y prueba para probar los algoritmos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# define the model\n",
    "model = HuberRegressor()\n",
    "#Entreno el modelo\n",
    "model_hu = model.fit(X_train, y_train)\n",
    "\n",
    "#Realizo una predicción\n",
    "Y_pred = regr.predict(X_test)\n",
    "\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y, model)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa490f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intercept:', model_hu.intercept_)\n",
    "print('Coefficients:', model_hu.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precisión del modelo:')\n",
    "print(model_hu.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c9649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
